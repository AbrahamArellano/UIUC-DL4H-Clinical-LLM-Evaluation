{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Reproduction of paper \"Do We Still Need Clinical Language Models?\"**\n",
        "\n",
        "\n",
        "Project work for CS 598 Deep Learning for Healthcare, UIUC, Spring 2025. We are reporducing the [Do We Still Need Clinical Language Models?](https://arxiv.org/pdf/2302.08091).\n"
      ],
      "metadata": {
        "id": "WwliiBmT0UU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Reproduction of the paper \\'Do we still need CLinical Language Models\\'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwX2W4ET0eF1",
        "outputId": "beb7e7b0-48f4-4b79-89ae-326379197185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reproduction of the paper 'Do we still need CLinical Language Models'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to google drive and mount the filesystems\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q56oNyi-3eSi",
        "outputId": "700d3814-448c-444b-c563-f672a9081345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Environment Setup and Configuration"
      ],
      "metadata": {
        "id": "FVDp3-Q7JNZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Import Dependencies"
      ],
      "metadata": {
        "id": "GZ-brOw3JTDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3ziRIr_Q-AO",
        "outputId": "06ae530c-d119-4107-9ce8-5ab8ac095a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Drive and mount the filesystem\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW  # Import AdamW from torch instead\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration, T5Tokenizer,\n",
        "    RobertaForSequenceClassification, RobertaTokenizer,\n",
        "    AutoModelForSequenceClassification, AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "import logging\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import gc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5stqobjfJXYP",
        "outputId": "4b2cfa5a-7b84-4e15-ab77-f7cec621eb3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Set Random Seeds for Reproducibility"
      ],
      "metadata": {
        "id": "teU-F4ZiMAvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set seed to 42 for reproducibility\n",
        "SEED = 42\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "UD9u5KaHMHIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Configure Paths and Validate Directory Structure"
      ],
      "metadata": {
        "id": "uBuglVSSMK3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base paths\n",
        "BASE_DIR = '/content/drive/MyDrive/DL4H-Project'\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
        "\n",
        "# Dataset paths\n",
        "MEDNLI_DIR = os.path.join(DATA_DIR, 'mednli')\n",
        "RADQA_DIR = os.path.join(DATA_DIR, 'radqa')\n",
        "CLIP_DIR = os.path.join(DATA_DIR, 'clip')\n",
        "\n",
        "# Model paths\n",
        "PRETRAINED_DIR = os.path.join(MODELS_DIR, 'pretrained')\n",
        "FINETUNED_DIR = os.path.join(MODELS_DIR, 'finetuned')\n",
        "\n",
        "# Constants\n",
        "MODEL_NAMES = [\n",
        "    't5-base',\n",
        "    't5-large',\n",
        "    'roberta-large',\n",
        "    'bio-clinical-bert',  # BioClinRoBERTa\n",
        "    'gatortron'\n",
        "]\n",
        "\n",
        "TASK_NAMES = ['mednli', 'radqa', 'clip']\n",
        "DATA_PERCENTAGES = ['full', '25pct', '10pct', '5pct', '1pct']\n",
        "\n",
        "# Helper function to validate directory exists\n",
        "def validate_dir(directory):\n",
        "    if os.path.exists(directory):\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Warning: Directory {directory} does not exist\")\n",
        "        return False\n",
        "\n",
        "# Validate directory structure\n",
        "print(\"Validating directory structure...\")\n",
        "directories_valid = True\n",
        "\n",
        "# Validate main directories\n",
        "for dir_path in [DATA_DIR, MODELS_DIR, RESULTS_DIR]:\n",
        "    if not validate_dir(dir_path):\n",
        "        directories_valid = False\n",
        "\n",
        "# Validate task directories\n",
        "for task in TASK_NAMES:\n",
        "    task_dir = os.path.join(DATA_DIR, task)\n",
        "    if not validate_dir(task_dir):\n",
        "        directories_valid = False\n",
        "\n",
        "if directories_valid:\n",
        "    print(\"✅ All required directories are present\")\n",
        "else:\n",
        "    print(\"⚠️ Some directories are missing - please check the warnings above\")\n",
        "\n",
        "# Helper function to get paths\n",
        "def get_dataset_path(task, percentage='full'):\n",
        "    \"\"\"Get the path to a specific dataset.\"\"\"\n",
        "    return os.path.join(DATA_DIR, task, percentage)\n",
        "\n",
        "def get_pretrained_model_path(model_name):\n",
        "    \"\"\"Get the path to a pretrained model.\"\"\"\n",
        "    # Determine if general or clinical model\n",
        "    if model_name in ['t5-base', 't5-large', 'roberta-large']:\n",
        "        model_type = 'general'\n",
        "    else:\n",
        "        model_type = 'clinical'\n",
        "    return os.path.join(PRETRAINED_DIR, model_type, model_name)\n",
        "\n",
        "def get_finetuned_model_path(model_name, task, percentage='full'):\n",
        "    \"\"\"Get the path to a finetuned model.\"\"\"\n",
        "    return os.path.join(FINETUNED_DIR, task, model_name, percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-IhHrmVMMAS",
        "outputId": "f451e80d-eb8b-463a-db8c-b39cf325e41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating directory structure...\n",
            "✅ All required directories are present\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 Setup Utility Functions"
      ],
      "metadata": {
        "id": "F2G_imroMdSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "def setup_logger(name, log_file, level=logging.INFO):\n",
        "    \"\"\"Set up a logger for experiment tracking.\"\"\"\n",
        "    handler = logging.FileHandler(log_file)\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    handler.setFormatter(formatter)\n",
        "\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(level)\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "    # Add console handler to see logs in Colab output\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setFormatter(formatter)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "# Create experiment logger\n",
        "log_path = os.path.join(BASE_DIR, 'experiment.log')\n",
        "logger = setup_logger('experiment_logger', log_path)\n",
        "logger.info(\"Starting experiment: Reproducing 'Do We Still Need Clinical Language Models?'\")\n",
        "\n",
        "# Memory management\n",
        "def clean_memory():\n",
        "    \"\"\"Clean up memory to avoid OOM errors.\"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Check hardware\n",
        "def check_hardware():\n",
        "    \"\"\"Check available hardware and return device to use.\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logger.info(f\"Using device: {device}\")\n",
        "\n",
        "    if device.type == \"cuda\":\n",
        "        logger.info(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "        logger.info(f\"CUDA memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
        "        logger.info(f\"CUDA memory cached: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
        "\n",
        "    return device\n",
        "\n",
        "# Get device\n",
        "device = check_hardware()\n",
        "\n",
        "# Experiment tracking\n",
        "class ExperimentTracker:\n",
        "    \"\"\"Helper class to track experiment progress and results.\"\"\"\n",
        "    def __init__(self, base_path):\n",
        "        self.base_path = base_path\n",
        "        self.results = {}\n",
        "        self.start_time = None\n",
        "\n",
        "    def start_experiment(self, model_name, task, data_percentage):\n",
        "        \"\"\"Start tracking a new experiment.\"\"\"\n",
        "        experiment_id = f\"{model_name}_{task}_{data_percentage}\"\n",
        "        self.results[experiment_id] = {\n",
        "            \"model\": model_name,\n",
        "            \"task\": task,\n",
        "            \"data_percentage\": data_percentage,\n",
        "            \"training_metrics\": {},\n",
        "            \"eval_metrics\": {},\n",
        "            \"status\": \"running\",\n",
        "            \"start_time\": time.time()\n",
        "        }\n",
        "        logger.info(f\"Started experiment: {experiment_id}\")\n",
        "        return experiment_id\n",
        "\n",
        "    def update_training_metrics(self, experiment_id, epoch, metrics):\n",
        "        \"\"\"Update training metrics for an experiment.\"\"\"\n",
        "        if experiment_id in self.results:\n",
        "            self.results[experiment_id][\"training_metrics\"][epoch] = metrics\n",
        "\n",
        "    def update_eval_metrics(self, experiment_id, metrics):\n",
        "        \"\"\"Update evaluation metrics for an experiment.\"\"\"\n",
        "        if experiment_id in self.results:\n",
        "            self.results[experiment_id][\"eval_metrics\"] = metrics\n",
        "\n",
        "    def complete_experiment(self, experiment_id):\n",
        "        \"\"\"Mark experiment as complete.\"\"\"\n",
        "        if experiment_id in self.results:\n",
        "            self.results[experiment_id][\"status\"] = \"completed\"\n",
        "            self.results[experiment_id][\"end_time\"] = time.time()\n",
        "            self.results[experiment_id][\"duration\"] = self.results[experiment_id][\"end_time\"] - self.results[experiment_id][\"start_time\"]\n",
        "            logger.info(f\"Completed experiment: {experiment_id} (Duration: {self.results[experiment_id]['duration']:.2f}s)\")\n",
        "\n",
        "    def save_results(self):\n",
        "        \"\"\"Save all results to disk.\"\"\"\n",
        "        results_path = os.path.join(self.base_path, \"experiment_results.json\")\n",
        "        with open(results_path, \"w\") as f:\n",
        "            json.dump(self.results, f, indent=2)\n",
        "        logger.info(f\"Saved experiment results to {results_path}\")\n",
        "\n",
        "# Create experiment tracker\n",
        "tracker = ExperimentTracker(RESULTS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "237Ti-AtMd0b",
        "outputId": "8606e582-e66a-48a7-84f7-2417fe0c9138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-08 18:55:57,314 - experiment_logger - INFO - Starting experiment: Reproducing 'Do We Still Need Clinical Language Models?'\n",
            "INFO:experiment_logger:Starting experiment: Reproducing 'Do We Still Need Clinical Language Models?'\n",
            "2025-04-08 18:55:57,701 - experiment_logger - INFO - Using device: cuda\n",
            "INFO:experiment_logger:Using device: cuda\n",
            "2025-04-08 18:55:57,740 - experiment_logger - INFO - CUDA device: Tesla T4\n",
            "INFO:experiment_logger:CUDA device: Tesla T4\n",
            "2025-04-08 18:55:57,742 - experiment_logger - INFO - CUDA memory allocated: 0.00 MB\n",
            "INFO:experiment_logger:CUDA memory allocated: 0.00 MB\n",
            "2025-04-08 18:55:57,743 - experiment_logger - INFO - CUDA memory cached: 0.00 MB\n",
            "INFO:experiment_logger:CUDA memory cached: 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 Validate Dataset Availability"
      ],
      "metadata": {
        "id": "qZ15_lFqMm6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset availability\n",
        "def check_dataset_availability():\n",
        "    \"\"\"Check if all required datasets are available and log stats.\"\"\"\n",
        "    dataset_files = {\n",
        "        \"mednli\": {\n",
        "            \"train\": os.path.join(MEDNLI_DIR, \"mli_train_v1.jsonl\"),\n",
        "            \"dev\": os.path.join(MEDNLI_DIR, \"mli_dev_v1.jsonl\"),\n",
        "            \"test\": os.path.join(MEDNLI_DIR, \"mli_test_v1.jsonl\")\n",
        "        },\n",
        "        \"radqa\": {\n",
        "            \"train\": os.path.join(RADQA_DIR, \"train.json\"),\n",
        "            \"dev\": os.path.join(RADQA_DIR, \"dev.json\"),\n",
        "            \"test\": os.path.join(RADQA_DIR, \"test.json\")\n",
        "        },\n",
        "        \"clip\": {\n",
        "            # Updated to match actual CLIP file structure\n",
        "            \"sentence_level\": os.path.join(CLIP_DIR, \"sentence_level.csv\"),\n",
        "            \"train_ids\": os.path.join(CLIP_DIR, \"train_ids.csv\"),\n",
        "            \"val_ids\": os.path.join(CLIP_DIR, \"val_ids.csv\"),\n",
        "            \"test_ids\": os.path.join(CLIP_DIR, \"test_ids.csv\")\n",
        "        }\n",
        "    }\n",
        "\n",
        "    dataset_availability = {}\n",
        "    dataset_stats = {}\n",
        "\n",
        "    for dataset, files in dataset_files.items():\n",
        "        dataset_availability[dataset] = {}\n",
        "        dataset_stats[dataset] = {}\n",
        "\n",
        "        for file_type, file_path in files.items():\n",
        "            dataset_availability[dataset][file_type] = os.path.exists(file_path)\n",
        "\n",
        "            # If file exists, try to gather statistics\n",
        "            if dataset_availability[dataset][file_type]:\n",
        "                try:\n",
        "                    if dataset == \"mednli\":\n",
        "                        # JSONL format\n",
        "                        with open(file_path, 'r') as f:\n",
        "                            lines = f.readlines()\n",
        "                            dataset_stats[dataset][file_type] = {\n",
        "                                'samples': len(lines),\n",
        "                                'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)\n",
        "                            }\n",
        "                    elif dataset == \"radqa\":\n",
        "                        # JSON format\n",
        "                        with open(file_path, 'r') as f:\n",
        "                            data = json.load(f)\n",
        "                            samples = sum(len(article['paragraphs']) for article in data['data'])\n",
        "                            dataset_stats[dataset][file_type] = {\n",
        "                                'samples': samples,\n",
        "                                'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)\n",
        "                            }\n",
        "                    elif dataset == \"clip\":\n",
        "                        # CSV format\n",
        "                        if file_type == \"sentence_level\":\n",
        "                            try:\n",
        "                                df = pd.read_csv(file_path)\n",
        "                                dataset_stats[dataset][file_type] = {\n",
        "                                    'samples': len(df),\n",
        "                                    'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)\n",
        "                                }\n",
        "                            except:\n",
        "                                dataset_stats[dataset][file_type] = {\n",
        "                                    'samples': 'unknown',\n",
        "                                    'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)\n",
        "                                }\n",
        "                        else:\n",
        "                            # ID files\n",
        "                            try:\n",
        "                                ids = pd.read_csv(file_path)\n",
        "                                dataset_stats[dataset][file_type] = {\n",
        "                                    'ids': len(ids),\n",
        "                                    'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)\n",
        "                                }\n",
        "                            except:\n",
        "                                dataset_stats[dataset][file_type] = {\n",
        "                                    'ids': 'unknown',\n",
        "                                    'file_size_mb': os.path.getsize(file_path) / (1024 * 1024)\n",
        "                                }\n",
        "                except Exception as e:\n",
        "                    dataset_stats[dataset][file_type] = {\n",
        "                        'samples': 'error',\n",
        "                        'file_size_mb': os.path.getsize(file_path) / (1024 * 1024) if os.path.exists(file_path) else 0,\n",
        "                        'error': str(e)\n",
        "                    }\n",
        "\n",
        "    # Log availability\n",
        "    all_available = True\n",
        "    for dataset, availability in dataset_availability.items():\n",
        "        if all(availability.values()):\n",
        "            logger.info(f\"✅ {dataset.upper()} dataset is fully available\")\n",
        "            for file_type, stats in dataset_stats[dataset].items():\n",
        "                if 'samples' in stats:\n",
        "                    if isinstance(stats['samples'], int):\n",
        "                        logger.info(f\"   - {file_type}: {stats['samples']} samples ({stats['file_size_mb']:.2f} MB)\")\n",
        "                    else:\n",
        "                        logger.info(f\"   - {file_type}: {stats.get('samples', 'unknown')} samples ({stats['file_size_mb']:.2f} MB)\")\n",
        "                elif 'ids' in stats:\n",
        "                    logger.info(f\"   - {file_type}: {stats['ids']} IDs ({stats['file_size_mb']:.2f} MB)\")\n",
        "        else:\n",
        "            all_available = False\n",
        "            logger.warning(f\"⚠️ {dataset.upper()} dataset is missing some files: {availability}\")\n",
        "            for file_type, exists in availability.items():\n",
        "                if not exists:\n",
        "                    logger.warning(f\"   - Missing: {dataset_files[dataset][file_type]}\")\n",
        "\n",
        "    if all_available:\n",
        "        print(\"✅ All required dataset files are available\")\n",
        "    else:\n",
        "        print(\"⚠️ Some dataset files are missing - see logs for details\")\n",
        "\n",
        "    return dataset_availability, dataset_stats\n",
        "\n",
        "# Check dataset availability\n",
        "dataset_availability, dataset_stats = check_dataset_availability()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpe_XLKJMn3y",
        "outputId": "a404ae89-5bbc-457a-a9eb-0ebfdaae42cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-08 18:56:07,550 - experiment_logger - INFO - ✅ MEDNLI dataset is fully available\n",
            "INFO:experiment_logger:✅ MEDNLI dataset is fully available\n",
            "2025-04-08 18:56:07,552 - experiment_logger - INFO -    - train: 11232 samples (10.52 MB)\n",
            "INFO:experiment_logger:   - train: 11232 samples (10.52 MB)\n",
            "2025-04-08 18:56:07,553 - experiment_logger - INFO -    - dev: 1395 samples (1.35 MB)\n",
            "INFO:experiment_logger:   - dev: 1395 samples (1.35 MB)\n",
            "2025-04-08 18:56:07,555 - experiment_logger - INFO -    - test: 1422 samples (1.30 MB)\n",
            "INFO:experiment_logger:   - test: 1422 samples (1.30 MB)\n",
            "2025-04-08 18:56:07,558 - experiment_logger - INFO - ✅ RADQA dataset is fully available\n",
            "INFO:experiment_logger:✅ RADQA dataset is fully available\n",
            "2025-04-08 18:56:07,559 - experiment_logger - INFO -    - train: 1606 samples (2.94 MB)\n",
            "INFO:experiment_logger:   - train: 1606 samples (2.94 MB)\n",
            "2025-04-08 18:56:07,560 - experiment_logger - INFO -    - dev: 204 samples (0.39 MB)\n",
            "INFO:experiment_logger:   - dev: 204 samples (0.39 MB)\n",
            "2025-04-08 18:56:07,562 - experiment_logger - INFO -    - test: 208 samples (0.40 MB)\n",
            "INFO:experiment_logger:   - test: 208 samples (0.40 MB)\n",
            "2025-04-08 18:56:07,565 - experiment_logger - INFO - ✅ CLIP dataset is fully available\n",
            "INFO:experiment_logger:✅ CLIP dataset is fully available\n",
            "2025-04-08 18:56:07,566 - experiment_logger - INFO -    - sentence_level: 107494 samples (13.18 MB)\n",
            "INFO:experiment_logger:   - sentence_level: 107494 samples (13.18 MB)\n",
            "2025-04-08 18:56:07,573 - experiment_logger - INFO -    - train_ids: 517 IDs (0.00 MB)\n",
            "INFO:experiment_logger:   - train_ids: 517 IDs (0.00 MB)\n",
            "2025-04-08 18:56:07,574 - experiment_logger - INFO -    - val_ids: 99 IDs (0.00 MB)\n",
            "INFO:experiment_logger:   - val_ids: 99 IDs (0.00 MB)\n",
            "2025-04-08 18:56:07,575 - experiment_logger - INFO -    - test_ids: 99 IDs (0.00 MB)\n",
            "INFO:experiment_logger:   - test_ids: 99 IDs (0.00 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All required dataset files are available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.6 Define Model Mapping and Specs - Updated for CLIP Structure"
      ],
      "metadata": {
        "id": "V59_cAnUPgLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model specifications including sources and parameter counts\n",
        "MODEL_SPECS = {\n",
        "    't5-base': {\n",
        "        'name': 't5-base',\n",
        "        'source': 'google/t5-base',\n",
        "        'parameters': 220_000_000,\n",
        "        'type': 'encoder-decoder',\n",
        "        'domain': 'general',\n",
        "        'tokenizer': T5Tokenizer,\n",
        "        'model_class': T5ForConditionalGeneration\n",
        "    },\n",
        "    't5-large': {\n",
        "        'name': 't5-large',\n",
        "        'source': 'google/t5-large',\n",
        "        'parameters': 770_000_000,\n",
        "        'type': 'encoder-decoder',\n",
        "        'domain': 'general',\n",
        "        'tokenizer': T5Tokenizer,\n",
        "        'model_class': T5ForConditionalGeneration\n",
        "    },\n",
        "    'roberta-large': {\n",
        "        'name': 'roberta-large',\n",
        "        'source': 'roberta-large',\n",
        "        'parameters': 345_000_000,\n",
        "        'type': 'encoder-only',\n",
        "        'domain': 'general',\n",
        "        'tokenizer': RobertaTokenizer,\n",
        "        'model_class': RobertaForSequenceClassification\n",
        "    },\n",
        "    'bio-clinical-bert': {\n",
        "        'name': 'bio-clinical-bert',\n",
        "        'source': 'emilyalsentzer/Bio_ClinicalBERT',\n",
        "        'parameters': 345_000_000,\n",
        "        'type': 'encoder-only',\n",
        "        'domain': 'clinical',\n",
        "        'tokenizer': AutoTokenizer,\n",
        "        'model_class': AutoModelForSequenceClassification\n",
        "    },\n",
        "    'gatortron': {\n",
        "        'name': 'gatortron',\n",
        "        'source': 'UFNLP/gatortron-base',  # Update if this is not the correct source\n",
        "        'parameters': 345_000_000,\n",
        "        'type': 'encoder-only',\n",
        "        'domain': 'clinical',\n",
        "        'tokenizer': AutoTokenizer,\n",
        "        'model_class': AutoModelForSequenceClassification\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define task specifications\n",
        "TASK_SPECS = {\n",
        "    'mednli': {\n",
        "        'name': 'mednli',\n",
        "        'type': 'classification',\n",
        "        'num_labels': 3,\n",
        "        'labels': ['entailment', 'neutral', 'contradiction'],\n",
        "        'metrics': ['accuracy'],\n",
        "        'encoder_input_format': '{premise} [SEP] {hypothesis}',\n",
        "        'encoder_decoder_input_format': 'mnli premise: {premise} hypothesis: {hypothesis}',\n",
        "        'max_length': 256\n",
        "    },\n",
        "    'radqa': {\n",
        "        'name': 'radqa',\n",
        "        'type': 'question-answering',\n",
        "        'metrics': ['f1', 'exact_match'],\n",
        "        'encoder_input_format': '{question} [SEP] {context}',\n",
        "        'encoder_decoder_input_format': 'question: {question} context: {context}',\n",
        "        'max_length': 512\n",
        "    },\n",
        "    'clip': {\n",
        "        'name': 'clip',\n",
        "        'type': 'multi-label-classification',\n",
        "        'num_labels': 7,\n",
        "        'labels': [\n",
        "            'appointment-related',\n",
        "            'medication-related',\n",
        "            'lab-related',\n",
        "            'patient-instructions',\n",
        "            'procedure-related',\n",
        "            'imaging-related',\n",
        "            'other'\n",
        "        ],\n",
        "        'metrics': ['micro_f1', 'macro_f1'],\n",
        "        'encoder_input_format': '{sentence}',\n",
        "        'encoder_decoder_input_format': 'clip: {sentence}',\n",
        "        'max_length': 256\n",
        "    }\n",
        "}\n",
        "\n",
        "# Check prerequisites for Phase 1\n",
        "def check_phase1_prerequisites():\n",
        "    prerequisites = {\n",
        "        \"Required Libraries\": {\n",
        "            \"torch\": torch.__version__ if 'torch' in globals() else \"Not installed\",\n",
        "            # Fix this line to check properly for transformers\n",
        "            \"transformers\": \"Installed\" if 'T5ForConditionalGeneration' in globals() else \"Not installed\",\n",
        "            \"pandas\": pd.__version__ if 'pd' in globals() else \"Not installed\",\n",
        "            \"numpy\": np.__version__ if 'np' in globals() else \"Not installed\",\n",
        "            \"matplotlib\": \"Installed\" if 'plt' in globals() else \"Not installed\",\n",
        "            \"sklearn\": \"Installed\" if 'f1_score' in globals() else \"Not installed\",\n",
        "        },\n",
        "        \"Google Drive Access\": \"Connected\" if os.path.exists(BASE_DIR) else \"Not connected\",\n",
        "        \"Dataset Files\": {\n",
        "            \"MedNLI Files\": all(dataset_availability.get(\"mednli\", {}).values()),\n",
        "            \"RadQA Files\": all(dataset_availability.get(\"radqa\", {}).values()),\n",
        "            # Updated for CLIP's actual structure\n",
        "            \"CLIP Files\": all(dataset_availability.get(\"clip\", {}).values())\n",
        "        },\n",
        "        \"GPU Availability\": \"Available\" if torch.cuda.is_available() else \"Not available\"\n",
        "    }\n",
        "\n",
        "    all_prerequisites_met = (\n",
        "        all(status != \"Not installed\" for status in prerequisites[\"Required Libraries\"].values()) and\n",
        "        prerequisites[\"Google Drive Access\"] == \"Connected\" and\n",
        "        all(prerequisites[\"Dataset Files\"].values())\n",
        "    )\n",
        "\n",
        "    print(\"Phase 1 Prerequisites Check:\")\n",
        "    print(\"----------------------------\")\n",
        "\n",
        "    for category, items in prerequisites.items():\n",
        "        if isinstance(items, dict):\n",
        "            print(f\"{category}:\")\n",
        "            for name, status in items.items():\n",
        "                status_symbol = \"✅\" if status not in [\"Not installed\", False] else \"❌\"\n",
        "                print(f\"  {status_symbol} {name}: {status}\")\n",
        "        else:\n",
        "            status_symbol = \"✅\" if items not in [\"Not installed\", \"Not connected\", False] else \"❌\"\n",
        "            print(f\"{status_symbol} {category}: {items}\")\n",
        "\n",
        "    if all_prerequisites_met:\n",
        "        print(\"\\n✅ All Phase 1 prerequisites are met!\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Some prerequisites are missing. Please address the issues marked with ❌\")\n",
        "\n",
        "    return all_prerequisites_met\n",
        "\n",
        "# Check Phase 1 prerequisites\n",
        "phase1_ready = check_phase1_prerequisites()\n",
        "\n",
        "print(\"\\nEnvironment setup \" + (\"complete!\" if phase1_ready else \"incomplete - see warnings above\"))\n",
        "\n",
        "# Print prerequisite files required for Phase 1\n",
        "print(\"\\nPrerequisite Files Required for Phase 1:\")\n",
        "print(\"---------------------------------------\")\n",
        "print(\"Dataset Files:\")\n",
        "print(\"1. MedNLI:\")\n",
        "print(\"   - \" + os.path.join(MEDNLI_DIR, \"mli_train_v1.jsonl\"))\n",
        "print(\"   - \" + os.path.join(MEDNLI_DIR, \"mli_dev_v1.jsonl\"))\n",
        "print(\"   - \" + os.path.join(MEDNLI_DIR, \"mli_test_v1.jsonl\"))\n",
        "print(\"2. RadQA:\")\n",
        "print(\"   - \" + os.path.join(RADQA_DIR, \"train.json\"))\n",
        "print(\"   - \" + os.path.join(RADQA_DIR, \"dev.json\"))\n",
        "print(\"   - \" + os.path.join(RADQA_DIR, \"test.json\"))\n",
        "print(\"3. CLIP: (updated file structure)\")\n",
        "print(\"   - \" + os.path.join(CLIP_DIR, \"sentence_level.csv\") + \" (main data file)\")\n",
        "print(\"   - \" + os.path.join(CLIP_DIR, \"train_ids.csv\") + \" (training split IDs)\")\n",
        "print(\"   - \" + os.path.join(CLIP_DIR, \"val_ids.csv\") + \" (validation split IDs)\")\n",
        "print(\"   - \" + os.path.join(CLIP_DIR, \"test_ids.csv\") + \" (test split IDs)\")\n",
        "print(\"\\nRequired Python Libraries:\")\n",
        "print(\"- torch\")\n",
        "print(\"- transformers\")\n",
        "print(\"- pandas\")\n",
        "print(\"- numpy\")\n",
        "print(\"- matplotlib\")\n",
        "print(\"- scikit-learn\")\n",
        "print(\"\\nHardware Requirements:\")\n",
        "print(\"- GPU with CUDA support (recommended)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfBYPkOdPhCJ",
        "outputId": "2a876f5b-37bf-477c-cbf5-4129161678dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1 Prerequisites Check:\n",
            "----------------------------\n",
            "Required Libraries:\n",
            "  ✅ torch: 2.6.0+cu124\n",
            "  ✅ transformers: Installed\n",
            "  ✅ pandas: 2.2.2\n",
            "  ✅ numpy: 2.0.2\n",
            "  ✅ matplotlib: Installed\n",
            "  ✅ sklearn: Installed\n",
            "✅ Google Drive Access: Connected\n",
            "Dataset Files:\n",
            "  ✅ MedNLI Files: True\n",
            "  ✅ RadQA Files: True\n",
            "  ✅ CLIP Files: True\n",
            "✅ GPU Availability: Available\n",
            "\n",
            "✅ All Phase 1 prerequisites are met!\n",
            "\n",
            "Environment setup complete!\n",
            "\n",
            "Prerequisite Files Required for Phase 1:\n",
            "---------------------------------------\n",
            "Dataset Files:\n",
            "1. MedNLI:\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/mednli/mli_train_v1.jsonl\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/mednli/mli_dev_v1.jsonl\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/mednli/mli_test_v1.jsonl\n",
            "2. RadQA:\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/radqa/train.json\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/radqa/dev.json\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/radqa/test.json\n",
            "3. CLIP: (updated file structure)\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/clip/sentence_level.csv (main data file)\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/clip/train_ids.csv (training split IDs)\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/clip/val_ids.csv (validation split IDs)\n",
            "   - /content/drive/MyDrive/DL4H-Project/data/clip/test_ids.csv (test split IDs)\n",
            "\n",
            "Required Python Libraries:\n",
            "- torch\n",
            "- transformers\n",
            "- pandas\n",
            "- numpy\n",
            "- matplotlib\n",
            "- scikit-learn\n",
            "\n",
            "Hardware Requirements:\n",
            "- GPU with CUDA support (recommended)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.7 Environment Verification and Setup Summary"
      ],
      "metadata": {
        "id": "gFdrScx7uyqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, install any missing libraries\n",
        "if \"transformers\" not in globals():\n",
        "    print(\"Installing transformers library...\")\n",
        "    !pip install transformers\n",
        "    print(\"Please restart runtime after installation\")\n",
        "\n",
        "# Verify environment and dataset access\n",
        "def summarize_environment():\n",
        "    \"\"\"Provide a summary of the environment and datasets for reference.\"\"\"\n",
        "\n",
        "    # System info\n",
        "    import platform\n",
        "    import torch\n",
        "\n",
        "    # Check if using GPU\n",
        "    if torch.cuda.is_available():\n",
        "        device_type = \"GPU\"\n",
        "        device_name = torch.cuda.get_device_name(0)\n",
        "        device_memory = f\"{torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\"\n",
        "    else:\n",
        "        device_type = \"CPU\"\n",
        "        device_name = \"N/A\"\n",
        "        device_memory = \"N/A\"\n",
        "\n",
        "    # Summarize system info\n",
        "    system_info = {\n",
        "        \"Python Version\": platform.python_version(),\n",
        "        \"OS\": platform.system(),\n",
        "        \"PyTorch Version\": torch.__version__,\n",
        "        \"Device Type\": device_type,\n",
        "        \"Device Name\": device_name,\n",
        "        \"Device Memory\": device_memory,\n",
        "        \"CUDA Version\": torch.version.cuda if torch.cuda.is_available() else \"N/A\",\n",
        "    }\n",
        "\n",
        "    # Summarize dataset stats\n",
        "    dataset_summary = {}\n",
        "    for dataset, stats in dataset_stats.items():\n",
        "        if dataset == \"mednli\":\n",
        "            dataset_summary[dataset] = {\n",
        "                \"Train Samples\": stats.get(\"train\", {}).get(\"samples\", \"unknown\"),\n",
        "                \"Dev Samples\": stats.get(\"dev\", {}).get(\"samples\", \"unknown\"),\n",
        "                \"Test Samples\": stats.get(\"test\", {}).get(\"samples\", \"unknown\")\n",
        "            }\n",
        "        elif dataset == \"radqa\":\n",
        "            dataset_summary[dataset] = {\n",
        "                \"Train Samples\": stats.get(\"train\", {}).get(\"samples\", \"unknown\"),\n",
        "                \"Dev Samples\": stats.get(\"dev\", {}).get(\"samples\", \"unknown\"),\n",
        "                \"Test Samples\": stats.get(\"test\", {}).get(\"samples\", \"unknown\")\n",
        "            }\n",
        "        elif dataset == \"clip\":\n",
        "            dataset_summary[dataset] = {\n",
        "                \"Total Samples\": stats.get(\"sentence_level\", {}).get(\"samples\", \"unknown\"),\n",
        "                \"Train IDs\": stats.get(\"train_ids\", {}).get(\"ids\", \"unknown\"),\n",
        "                \"Val IDs\": stats.get(\"val_ids\", {}).get(\"ids\", \"unknown\"),\n",
        "                \"Test IDs\": stats.get(\"test_ids\", {}).get(\"ids\", \"unknown\")\n",
        "            }\n",
        "\n",
        "    # Print system info\n",
        "    print(\"System Information:\")\n",
        "    print(\"-----------------\")\n",
        "    for key, value in system_info.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    # Print dataset summary\n",
        "    print(\"\\nDataset Summary:\")\n",
        "    print(\"---------------\")\n",
        "    for dataset, summary in dataset_summary.items():\n",
        "        print(f\"{dataset.upper()}:\")\n",
        "        for key, value in summary.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "    # Return all information for logging\n",
        "    return {\n",
        "        \"system_info\": system_info,\n",
        "        \"dataset_summary\": dataset_summary\n",
        "    }\n",
        "\n",
        "# Run the summary\n",
        "if phase1_ready:\n",
        "    env_summary = summarize_environment()\n",
        "\n",
        "    # Log the summary\n",
        "    logger.info(\"Environment setup complete\")\n",
        "    logger.info(f\"System Information: {json.dumps(env_summary['system_info'])}\")\n",
        "    logger.info(f\"Dataset Summary: {json.dumps(env_summary['dataset_summary'])}\")\n",
        "\n",
        "    print(\"\\nPhase 1 Complete: Environment is ready for Phase 2 (Dataset Processing)\")\n",
        "    print(\"Note: Using T4 GPU for training and inference\")\n",
        "else:\n",
        "    print(\"\\n⚠️ Please fix the issues above before proceeding to Phase 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaoiDrecu0Fc",
        "outputId": "9e2caa5c-b488-4af4-8bcd-fc07a96c7b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing transformers library...\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-08 19:11:55,841 - experiment_logger - INFO - Environment setup complete\n",
            "INFO:experiment_logger:Environment setup complete\n",
            "2025-04-08 19:11:55,844 - experiment_logger - INFO - System Information: {\"Python Version\": \"3.11.11\", \"OS\": \"Linux\", \"PyTorch Version\": \"2.6.0+cu124\", \"Device Type\": \"GPU\", \"Device Name\": \"Tesla T4\", \"Device Memory\": \"14.74 GB\", \"CUDA Version\": \"12.4\"}\n",
            "INFO:experiment_logger:System Information: {\"Python Version\": \"3.11.11\", \"OS\": \"Linux\", \"PyTorch Version\": \"2.6.0+cu124\", \"Device Type\": \"GPU\", \"Device Name\": \"Tesla T4\", \"Device Memory\": \"14.74 GB\", \"CUDA Version\": \"12.4\"}\n",
            "2025-04-08 19:11:55,846 - experiment_logger - INFO - Dataset Summary: {\"mednli\": {\"Train Samples\": 11232, \"Dev Samples\": 1395, \"Test Samples\": 1422}, \"radqa\": {\"Train Samples\": 1606, \"Dev Samples\": 204, \"Test Samples\": 208}, \"clip\": {\"Total Samples\": 107494, \"Train IDs\": 517, \"Val IDs\": 99, \"Test IDs\": 99}}\n",
            "INFO:experiment_logger:Dataset Summary: {\"mednli\": {\"Train Samples\": 11232, \"Dev Samples\": 1395, \"Test Samples\": 1422}, \"radqa\": {\"Train Samples\": 1606, \"Dev Samples\": 204, \"Test Samples\": 208}, \"clip\": {\"Total Samples\": 107494, \"Train IDs\": 517, \"Val IDs\": 99, \"Test IDs\": 99}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please restart runtime after installation\n",
            "System Information:\n",
            "-----------------\n",
            "Python Version: 3.11.11\n",
            "OS: Linux\n",
            "PyTorch Version: 2.6.0+cu124\n",
            "Device Type: GPU\n",
            "Device Name: Tesla T4\n",
            "Device Memory: 14.74 GB\n",
            "CUDA Version: 12.4\n",
            "\n",
            "Dataset Summary:\n",
            "---------------\n",
            "MEDNLI:\n",
            "  Train Samples: 11232\n",
            "  Dev Samples: 1395\n",
            "  Test Samples: 1422\n",
            "RADQA:\n",
            "  Train Samples: 1606\n",
            "  Dev Samples: 204\n",
            "  Test Samples: 208\n",
            "CLIP:\n",
            "  Total Samples: 107494\n",
            "  Train IDs: 517\n",
            "  Val IDs: 99\n",
            "  Test IDs: 99\n",
            "\n",
            "Phase 1 Complete: Environment is ready for Phase 2 (Dataset Processing)\n",
            "Note: Using T4 GPU for training and inference\n"
          ]
        }
      ]
    }
  ]
}